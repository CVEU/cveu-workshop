<!-- Purpose Section -->
<section id="program" class="content-section text-left">
    <div class="download-section">
        <div class="container">
            <div class="col-lg-8 col-lg-offset-2">
                <h2 class="text-center">Program</h2>
                <p>Discuss recent advances in video understanding in the realm of video creation and editing. Some of
                    the topics that we plan to discuss are:</p>
                <p>Would AI kill video editing jobs?</p>
                <p>Can AI make humans reduce the cost of video productions?</p>
                <p>Are there any biases and threads by using AI in this field?</p>
                <h3>Detailed program: (tentative)</h3>
                <table class="table table-bordered" style="font-size: 1.25em;">
                    <thead>
                        <tr>
                            <th scope="col">Tentative Schedule</th>
                            <th scope="col">Pacific Daylight Time<br />2021-10-17 08:00 AM</th>
                            <th scope="col"><span class="local-timezone"></span><br /><span class="local-day"
                                    data-time="2021-10-17T08:00:00-07:00"></span></th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <th scope="row">Introduction</th>
                            <td>08:00 AM - 08:30 AM</td>
                            <td><span class="local-time" data-time="2021-10-17T08:00:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T08:30:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Keynote I (by <span class="hl-blue">Prof. James E. Cutting</span>)
                                <br />
                                <a class="hl-green" href="#!" data-toggle="modal" data-target="#james-keynote">The Event
                                    Structure of Popular Movies</a>
                            </th>
                            <td>08:30 AM - 09:15 AM</td>
                            <td><span class="local-time" data-time="2021-10-17T08:30:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T09:15:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Keynote II (by <span class="hl-blue">Prof. Marc Christie</span>)
                                <br />
                                <a class="hl-green" href="#!" data-toggle="modal" data-target="#marc-keynote">Towards
                                    Computational Cinematography: what's left and what right?</a>
                            </th>
                            <td>09:15 AM - 10:00 AM</td>
                            <td><span class="local-time" data-time="2021-10-17T09:15:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T10:00:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Break</th>
                            <td>10:00 AM - 10:15 AM</td>
                            <td><span class="local-time" data-time="2021-10-17T10:00:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T10:15:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Keynote III (by <span class="hl-blue">Prof. Irfan Essa</span>)
                                <br />
                                <a class="hl-green" href="#!" data-toggle="modal" data-target="#irfan-keynote">AI for
                                    Video Creation</a>
                            </th>
                            <td>10:15 AM - 11:00 AM</td>
                            <td><span class="local-time" data-time="2021-10-17T10:15:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T11:00:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Panel Discussion</th>
                            <td>11:00 AM - 12:00 PM</td>
                            <td><span class="local-time" data-time="2021-10-17T11:00:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T12:00:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Lunch Break</th>
                            <td>12:00 PM - 13:00 PM</td>
                            <td><span class="local-time" data-time="2021-10-17T12:00:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T13:00:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Keynote IV (by <span class="hl-blue">Prof. Angjoo Kanazawa</span>)
                                <br />
                                <a class="hl-green" href="#!" data-toggle="modal" data-target="#angjoo-keynote">Infinite
                                    Nature: Perpetual View Generation of Natural Scenes from
                                    a Single Image
                                </a>
                            </th>
                            <td>13:00 PM - 13:45 PM</td>
                            <td><span class="local-time" data-time="2021-10-17T13:00:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T13:45:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Keynote V (by <span class="hl-blue">Prof. Maneesh Agrawala</span>)
                                <br />
                                <a class="hl-green" href="#!" data-toggle="modal" data-target="#maneesh-keynote">Making
                                    (and Breaking) Video</a>
                            </th>
                            <td>13:45 PM - 14:30 PM</td>
                            <td><span class="local-time" data-time="2021-10-17T13:45:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T14:30:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Break</th>
                            <td>14:30 PM - 14:45 PM</td>
                            <td><span class="local-time" data-time="2021-10-17T14:30:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T14:45:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Invited Works I + QA</th>
                            <td>14:45 PM - 15:30 PM</td>
                            <td><span class="local-time" data-time="2021-10-17T14:45:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T15:30:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Invited Works II + QA</th>
                            <td>15:30 PM - 16:15 PM</td>
                            <td><span class="local-time" data-time="2021-10-17T15:30:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T16:15:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Industry Spotlight I (by <span class="hl-blue">Joon-Young - Adobe</span>)
                                <br />
                                <a class="hl-green" href="#!" data-toggle="modal" data-target="#adobe-keynote">Video
                                    Segmentation for Video Editing</a>
                            </th>
                            <td>16:15 PM - 16:30 PM</td>
                            <td><span class="local-time" data-time="2021-10-17T16:15:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T16:30:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Industry Spotlight II (by <span class="hl-blue">Anastasis - RunwayML</span>)
                                <br />
                                <a class="hl-green" href="#!" data-toggle="modal" data-target="#runway-keynote">Building
                                    Human-in-the-Loop Machine Learning Tools for Video Editing</a>
                            </th>
                            <td>16:30 PM - 16:45 PM</td>
                            <td><span class="local-time" data-time="2021-10-17T16:30:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T16:45:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Industry Spotlight III (by <span class="hl-blue">Synopsis</span>)
                                <br />
                                <a class="hl-green" href="#!" data-toggle="modal"
                                    data-target="#synopsis-keynote">CinemaNet: Building Better Cinematic Workflows with
                                    Creative Metadata</a>
                            </th>
                            <td>16:45 PM - 17:00 PM</td>
                            <td><span class="local-time" data-time="2021-10-17T16:45:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T17:00:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Industry Spotlight VI (by <span class="hl-blue">Fernando Amat Gil -
                                    Netflix</span>)
                                <br />
                                <a class="hl-green" href="#!" data-toggle="modal" data-target="#netflix-keynote">Can
                                    Machine Learning Assist in Making Better Trailers?</a>
                            </th>
                            <td>17:00 PM - 17:15 PM</td>
                            <td><span class="local-time" data-time="2021-10-17T17:00:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T17:15:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Industry Spotlight V (by <span class="hl-blue">Xintao Wang -
                                    Tencent ARC</span>)
                                <br />
                                <a class="hl-green" href="#!" data-toggle="modal" data-target="#tencent-keynote">Tencent
                                    ARC: The Wonderland of Video Editing and Creation Algorithms</a>
                            </th>
                            <td>17:15 PM - 17:30 PM</td>
                            <td><span class="local-time" data-time="2021-10-17T17:15:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T17:30:00-07:00"></span></td>
                        </tr>
                        <tr>
                            <th scope="row">Closing Remarks</th>
                            <td>17:30 PM - 17:45 PM</td>
                            <td><span class="local-time" data-time="2021-10-17T17:30:00-07:00"></span> - <span
                                    class="local-time" data-time="2021-10-17T17:45:00-07:00"></span></td>
                        </tr>
                    </tbody>
                </table>

                <br />
                <h3>Accepted Papers & Invited Works</h3>
                <table class="table table-bordered" style="font-size: 1.25em;">
                    <thead>
                        <tr>
                            <th scope="col">Title</th>
                            <th scope="col">Speaker</th>
                            <th scope="col">Resource</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <th scope="row">[14:45 PM - 14:55 PM] VLG-Net: Video-Language Graph Matching Network for
                                Video Grounding</th>
                            <td>Mattia Soldan</td>
                            <td><a href="src/vlg_net.pdf" traget="_blank">Paper</a>
                                &nbsp; <a href="https://www.youtube.com/watch?v=hj3XCtUn22E"
                                    traget="_blank">Video(YouTube)</a>&nbsp; <a
                                    href="https://www.bilibili.com/video/BV1mF411Y7VL/"
                                    traget="_blank">Video(Bilibili)</a></td>
                        </tr>
                        <tr>
                            <th scope="row">[14:55 PM - 15:00 PM] Video Transformer Network</th>
                            <td>Daniel Neimark</td>
                            <td><a href="src/vtn.pdf" traget="_blank">Paper</a> &nbsp; <a href="src/vtn_supp.pdf"
                                    traget="_blank">Supp</a>
                                &nbsp; <a href="https://www.youtube.com/watch?v=0juI0rHs038"
                                    traget="_blank">Video(YouTube)</a>&nbsp; <a
                                    href="https://www.bilibili.com/video/BV1hh411b7Q9/"
                                    traget="_blank">Video(Bilibili)</a></td>
                        </tr>
                        <tr>
                            <th scope="row">[15:00 PM - 15:05 PM] TSP: Temporally-Sensitive Pretraining of Video
                                Encoders for Localization
                                Tasks</th>
                            <td>Humam Alwassel</td>
                            <td><a href="src/tsp.pdf" traget="_blank">Paper</a>&nbsp; <a href="src/tsp_supp.pdf"
                                    traget="_blank">Supp</a>&nbsp; <a href="https://www.youtube.com/watch?v=oLcL3vY_UFM"
                                    traget="_blank">Video(YouTube)</a>&nbsp; <a
                                    href="https://www.bilibili.com/video/BV1kU4y1F7dv/"
                                    traget="_blank">Video(Bilibili)</a></td>
                        </tr>
                        <tr>
                            <th scope="row">[15:05 PM - 15:10 PM] Face, Body, Voice: Video Person-Clustering with
                                Multiple Modalities</th>
                            <td>Andrew Brown</td>
                            <td><a href="src/face_body_voice.pdf" traget="_blank">Paper</a>&nbsp; <a
                                    href="https://www.youtube.com/watch?v=ho58dTFO9kg"
                                    traget="_blank">Video(YouTube)</a>&nbsp; <a
                                    href="https://www.bilibili.com/video/BV1n44y147No/"
                                    traget="_blank">Video(Bilibili)</a></td>
                        </tr>
                        <tr>
                            <th scope="row">[15:10 PM - 15:15 PM] Video Contrastive Learning with Global Context</th>
                            <td>Haofei Kuang</td>
                            <td><a href="src/vcl.pdf" traget="_blank">Paper</a>&nbsp; <a
                                    href="https://www.youtube.com/watch?v=lJhQxI6VJMM"
                                    traget="_blank">Video(YouTube)</a>&nbsp; <a
                                    href="https://www.bilibili.com/video/BV1mq4y197ri/"
                                    traget="_blank">Video(Bilibili)</a></td>
                        </tr>
                        <tr>
                            <th scope="row">[15:15 PM - 15:20 PM] Plots to Previews: Towards Automatic Movie Preview
                                Retrieval using Publicly
                                Available Meta-data</th>
                            <td>Bhagyashree Gaikwad</td>
                            <td><a href="src/plots_to_previews.pdf" traget="_blank">Paper</a>&nbsp; <a
                                    href="src/plots_to_previews_supp.pdf" traget="_blank">Supp</a>&nbsp; <a
                                    href="https://www.youtube.com/watch?v=XyX7LEglbn0"
                                    traget="_blank">Video(YouTube)</a>&nbsp; <a
                                    href="https://www.bilibili.com/video/BV1ir4y1y7vq/"
                                    traget="_blank">Video(Bilibili)</a></td>
                        </tr>
                        <tr>
                            <th scope="row">[15:20 PM - 15:25 PM] Learning Where to Cut from Edited Videos</th>
                            <td>Yuzhong Huang</td>
                            <td><a href="src/cut.pdf" traget="_blank">Paper</a>
                                &nbsp; <a href="https://www.youtube.com/watch?v=GuWviDkHX1Q"
                                    traget="_blank">Video(YouTube)</a>&nbsp; <a
                                    href="https://www.bilibili.com/video/BV1CT4y1o7jZ/"
                                    traget="_blank">Video(Bilibili)</a></td>
                        </tr>
                        <tr>
                            <th scope="row">[15:25 PM - 15:30 PM] QA</th>
                            <td></td>
                            <td></td>
                        </tr>
                        <tr>
                            <th scope="row">[15:30 PM - 15:42 PM] Paint Transformer: Feed Forward Neural Painting with
                                Stroke Prediction</th>
                            <td>Songhua Liu</td>
                            <td><a href="https://arxiv.org/pdf/2108.03798.pdf" traget="_blank">Paper
                                    &nbsp; <a href="https://www.youtube.com/watch?v=umFKiwuvD6w"
                                        traget="_blank">Video(YouTube)</a>&nbsp; <a
                                        href="https://www.bilibili.com/video/BV1Eh411n7ok/"
                                        traget="_blank">Video(Bilibili)</a></td>
                        </tr>
                        <tr>
                            <th scope="row">[15:42 PM - 15:47 PM] Boundary-sensitive Pre-training for Temporal
                                Localization in Videos</th>
                            <td>Mengmeng Xu</td>
                            <td><a href="https://arxiv.org/pdf/2011.10830.pdf" traget="_blank">Paper</a>
                                &nbsp; <a href="https://www.youtube.com/watch?v=dFghiMRvj-U"
                                    traget="_blank">Video(YouTube)</a>&nbsp; <a
                                    href="https://www.bilibili.com/video/BV1s34y1m7FN/"
                                    traget="_blank">Video(Bilibili)</a></td>
                        </tr>
                        <tr>
                            <th scope="row">[15:47 PM - 15:52 PM] Editing like Humans: A Contextual, Multimodal
                                Framework for Automated Video
                                Editing</th>
                            <td>Patrick Adelman</td>
                            <td><a href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/papers/Koorathota_Editing_Like_Humans_A_Contextual_Multimodal_Framework_for_Automated_Video_CVPRW_2021_paper.pdf"
                                    traget="_blank">Paper</a>&nbsp; <a
                                    href="https://www.youtube.com/watch?v=pzbPu2v63Sc"
                                    traget="_blank">Video(YouTube)</a>&nbsp; <a
                                    href="https://www.bilibili.com/video/BV1TR4y1J7yK/"
                                    traget="_blank">Video(Bilibili)</a></td>
                        </tr>
                        <tr>
                            <th scope="row">[15:52 PM - 15:57 PM] ASCNet: Self-supervised Video Representation Learning
                                with Appearance-Speed
                                Consistency</th>
                            <td>Wenhao Wu</td>
                            <td><a href="https://arxiv.org/pdf/2106.02342.pdf" traget="_blank">Paper</a>&nbsp; <a
                                    href="https://www.youtube.com/watch?v=yRmdu2CmKCw"
                                    traget="_blank">Video(YouTube)</a>&nbsp; <a
                                    href="https://www.bilibili.com/video/BV1ju411f7CH/"
                                    traget="_blank">Video(Bilibili)</a></td>
                        </tr>
                        <tr>
                            <th scope="row">[15:57 PM - 16:02 PM] AniVid: A Novel Anime Video Dataset with Applications
                                in Animation</th>
                            <td>Kai E Gangi</td>
                            <td><a href="src/ani_vid.pdf" traget="_blank">Paper</a>&nbsp; <a
                                    href="https://www.youtube.com/watch?v=IuRzRVB7fxc"
                                    traget="_blank">Video(YouTube)</a>&nbsp; <a
                                    href="https://www.bilibili.com/video/BV1Fr4y1179v/"
                                    traget="_blank">Video(Bilibili)</a></td>
                        </tr>
                        <tr>
                            <th scope="row">[16:02 PM - 16:06 PM] High-Level Features for Movie Style Understanding</th>
                            <td>Robin Courant</td>
                            <td><a href="src/movie_style.pdf" traget="_blank">Paper</a>&nbsp; <a
                                    href="src/movie_style_supp.pdf" traget="_blank">Supp</a>&nbsp; <a
                                    href="https://www.youtube.com/watch?v=7CXdtfdQxZs"
                                    traget="_blank">Video(YouTube)</a>&nbsp; <a
                                    href="https://www.bilibili.com/video/BV1JQ4y1z7s9/"
                                    traget="_blank">Video(Bilibili)</a></td>
                        </tr>
                        <tr>
                            <th scope="row">[16:06 PM - 16:10 PM] Re-enacting video shots with fictional characters
                            </th>
                            <td>Joanna Materzynska</td>
                            <td><a href="src/re_enacting.pdf" traget="_blank">Paper</a>&nbsp; <a
                                    href="https://www.youtube.com/watch?v=Low8ScDl9UU"
                                    traget="_blank">Video(YouTube)</a>&nbsp; <a
                                    href="https://www.bilibili.com/video/BV1Lu411f7V5/"
                                    traget="_blank">Video(Bilibili)</a></td>
                        </tr>
                        <tr>
                            <th scope="row">[16:10 PM - 16:15 PM] QA</th>
                            <td></td>
                            <td></td>
                        </tr>
                    </tbody>
                </table>

                <br />
                <h3>Keynote Speakers</h3>
                <div class="row">
                    {% for person in site.speaker %}
                    <div class="col-lg-2">

                        <div class="person-image">
                            <img src="{{ person.avatar }}" class="person-avatar" width="100%" height="100%">
                        </div>
                        <div class="person-meta">
                            <span class="person-name"><a href="{{ person.website }}" target="_blank">{{ person.name
                                    }}</a></span>
                            <br />
                            <span class="person-affliation">{{ person.affliation }}</span>
                        </div>
                    </div>
                    {% endfor %}
                </div>

                <br />
                <h3>Industry Spotlights</h3>
                <div class="row">
                    {% for company in site.industry %}
                    <img class="logo-box" src="{{ company.logo }}" width="auto" height="70px">
                    {% endfor %}
                </div>
                <!-- <p>More to come ...</p> -->
            </div>
        </div>
    </div>
</section>


<!-- Modal -->
<div class="modal fade" id="james-keynote" tabindex="-1" role="dialog" aria-labelledby="james-keynote"
    aria-hidden="true">
    <div class="modal-dialog" role="document">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">The Event Structure of Popular Movies
                </h5>
            </div>
            <div class="modal-body">
                The world around us parses itself into separate pieces we call events. Days are the most obvious. Having
                evolved in that
                world we carry on with this procedure, making finer and finer segmentations adapted to our daily lives –
                commutes,
                conversations, meals, and—yes— conferences are all events, many with subevents within them. This
                segmentation process,
                and the hierarchical structures that it makes, aid our memory (for both order and content), which is not
                well-adapted to
                continuous and un-demarcated flows.
                <br />
                Stories contain the events that we tell others. They form the basis of our education system, our
                politics and religions,
                and ramify the network of our friendships. And popular cinema tells stories too. I have gathered data
                from nearly 300
                movies spanning a century and have found many things relevant to stories. They can be divided in parts,
                typically four
                (but ranging from three to five). Each of those parts is divisible into scenes and what I call syntagmas
                (collections of
                related, typically alternating, subscenes). My presentation outlines the structures of larger narrative
                parts, scenes,
                and syntagmas and how they serve the memory and comprehension of the viewer.
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-primary" data-dismiss="modal">Close</button>
            </div>
        </div>
    </div>
</div>

<div class="modal fade" id="marc-keynote" tabindex="-1" role="dialog" aria-labelledby="marc-keynote" aria-hidden="true">
    <div class="modal-dialog" role="document">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">Towards Computational Cinematography: what's left and what right?</h5>
            </div>
            <div class="modal-body">
                This talk will present past and ongoing work on computational models related to film editing and
                cinematography.
                Stemming from early contributions in continuity editing for 3D animated scenes, we will explore how film
                editing
                patterns and high-level narrative structures help to both analyse and generate cinematic sequences. We
                will show the
                importance of dedicated computational saliency techniques, and how these can augment our understanding
                of correlations
                between camera techniques and spectators gaze. We will then shape the key requirements to support
                designers in the
                creation and edition of cinematic sequences, and show how this calls for strong interdisciplinary
                approaches than can
                link discourse linguistics, cognition and computer science.
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-primary" data-dismiss="modal">Close</button>
            </div>
        </div>
    </div>
</div>

<div class="modal fade" id="irfan-keynote" tabindex="-1" role="dialog" aria-labelledby="irfan-keynote"
    aria-hidden="true">
    <div class="modal-dialog" role="document">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">AI for Video Creation</h5>
            </div>
            <div class="modal-body">
                TBD
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-primary" data-dismiss="modal">Close</button>
            </div>
        </div>
    </div>
</div>

<div class="modal fade" id="angjoo-keynote" tabindex="-1" role="dialog" aria-labelledby="angjoo-keynote"
    aria-hidden="true">
    <div class="modal-dialog" role="document">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">Infinite Nature: Perpetual View Generation of Natural Scenes from a Single Image
                </h5>
            </div>
            <div class="modal-body">
                What is a video if not a slice of the underlying 4D world seen from a camera trajectory? In this talk I
                will discuss our
                new work that introduces the problem of Perpetual View Generation—long-range generation of novel views
                corresponding to
                an arbitrarily long camera trajectory. We propose a hybrid approach that takes advantage of 3D geometric
                inductive bias
                and image synthesis, resulting in a controllable long-range video generation method from a single image
                that can be
                learned from videos without any manual annotation. We focus on natural scenes where an abundant amount
                of aerial footage
                is available and introduce a new nature video dataset.
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-primary" data-dismiss="modal">Close</button>
            </div>
        </div>
    </div>
</div>

<div class="modal fade" id="maneesh-keynote" tabindex="-1" role="dialog" aria-labelledby="maneesh-keynote"
    aria-hidden="true">
    <div class="modal-dialog" role="document">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">Making (and Breaking) Video</h5>
            </div>
            <div class="modal-body">
                Video has become a primary medium for communicating ideas,
                making sense of information and telling stories. It is central to making,
                establishing and conveying human cultures throughout the world. Whether it is
                a soap opera, broadcast news, cinematic film, or even viral YouTube clips, the
                most watched video is engaging and usually involves careful attention to production.
                Technological advances have made it easy to capture video using our mobile devices.
                But the raw media rarely tells a compelling story. In this talk I'll present
                recent projects that aim to significantly reduce the effort required to edit and produce
                high-quality video. Our tools are designed to let storytellers specify high-level objectives
                and let the computer handle lower-level details in putting together the raw materials.
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-primary" data-dismiss="modal">Close</button>
            </div>
        </div>
    </div>
</div>

<div class="modal fade" id="adobe-keynote" tabindex="-1" role="dialog" aria-labelledby="adobe-keynote"
    aria-hidden="true">
    <div class="modal-dialog" role="document">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">Video Segmentation for Video Editing</h5>
            </div>
            <div class="modal-body">
                For the past few years, I have been working on video segmentation with a specific focus on video editing
                applications.
                In this talk, I plan to walk through my research journey on video segmentation.
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-primary" data-dismiss="modal">Close</button>
            </div>
        </div>
    </div>
</div>

<div class="modal fade" id="runway-keynote" tabindex="-1" role="dialog" aria-labelledby="runway-keynote"
    aria-hidden="true">
    <div class="modal-dialog" role="document">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">Building Human-in-the-Loop Machine Learning Tools for Video Editing</h5>
            </div>
            <div class="modal-body">
                TBD
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-primary" data-dismiss="modal">Close</button>
            </div>
        </div>
    </div>
</div>

<div class="modal fade" id="synopsis-keynote" tabindex="-1" role="dialog" aria-labelledby="synopsis-keynote"
    aria-hidden="true">
    <div class="modal-dialog" role="document">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">CinemaNet: Building Better Cinematic Workflows with Creative Metadata</h5>
            </div>
            <div class="modal-body">
                TBD
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-primary" data-dismiss="modal">Close</button>
            </div>
        </div>
    </div>
</div>

<div class="modal fade" id="netflix-keynote" tabindex="-1" role="dialog" aria-labelledby="netflix-keynote"
    aria-hidden="true">
    <div class="modal-dialog" role="document">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">Can machine learning assist in making better trailers?</h5>
            </div>
            <div class="modal-body">
                Netflix is currently the largest cinematic studio in the world generating hundreds of original movies
                and shows a year.
                Most of those titles are unknown to the user until they are featured in the homepage. Trailers are one
                of the most
                classical forms used to promote video content and to help users make informed choices. However, the
                making of a trailer
                is a complex subjective creative process and it is hard to scale up. In this talk we will present
                different ways in
                which machine learning can help in that process, in order for a more effective and efficient trailer
                creation.
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-primary" data-dismiss="modal">Close</button>
            </div>
        </div>
    </div>
</div>

<div class="modal fade" id="tencent-keynote" tabindex="-1" role="dialog" aria-labelledby="tencent-keynote"
    aria-hidden="true">
    <div class="modal-dialog" role="document">
        <div class="modal-content">
            <div class="modal-header">
                <h5 class="modal-title">Tencent ARC: The Wonderland of Video Editing and Creation Algorithms</h5>
            </div>
            <div class="modal-body">
                TBD
            </div>
            <div class="modal-footer">
                <button type="button" class="btn btn-primary" data-dismiss="modal">Close</button>
            </div>
        </div>
    </div>
</div>